# Parameters to setup experiment.
experiment:
  # Unique experiment identifier
  id: girl4_00236_dense
  # Experiment logs will be stored at "logdir"/"id"
  logdir: ./logs/girl4_style
  # Seed for random number generators (for repeatability).
  randomseed: 42  # Cause, why not?
  # Number of training iterations.
  train_iters: 60000
  # Number of training iterations after which to validate.
  validate_every: 500
  # Number of training iterations after which to checkpoint.
  save_every: 100
  # Number of training iterations after which to print progress.
  print_every: 100
  device: 0
  device_backup: 0
  g_step: 3
  fix_density: True
  no_coarse_color: True
  extreme_makeup: True
  concat_vgg: False
  concat_global: True
  feat_dim: 32

# Dataset parameters.
dataset:
  # Type of dataset (Blender vs LLFF vs DeepVoxels vs something else)
  type: blender
  # Base directory of dataset.
  basedir: ./dataset/girl4
  style_id: '00236'
  #basedir: real_data/andrei_1_light
  #basedir: real_data/debug
  # Optionally, provide a path to the pre-cached dataset dir. This
  # overrides the other dataset options.
  #cachedir: cache/flame_sample
  # For the Blender datasets (synthetic), optionally return images
  # at half the original resolution of 800 x 800, to save space.
  half_res: True
  # Stride (include one per "testskip" images in the dataset).
  testskip: 1
  # Do not use NDC (normalized device coordinates). Usually True for
  # synthetic (Blender) datasets.
  no_ndc: True
  # Near clip plane (clip all depth values closer than this threshold).
  near: 0.2
  # Far clip plane (clip all depth values farther than this threshold).
  far: 0.8
  scale: 0.5  # compared with 512

# Model parameters.
models:
  # Coarse model.
  coarse:
    # Name of the torch.nn.Module class that implements the model.
    type: ConditionalBlendshapePaperNeRFModel
    # Number of layers in the model.
    num_layers: 4
    # Number of hidden units in each layer of the MLP (multi-layer
    # perceptron).
    hidden_size: 256
    # Add a skip connection once in a while. Note: This parameter
    # won't take affect unless num_layers > skip_connect_every.
    skip_connect_every: 3
    # Whether to include the position (xyz) itself in its positional
    # encoding.
    include_input_xyz: True
    # Whether or not to perform log sampling in the positional encoding
    # of the coordinates.
    log_sampling_xyz: True
    # Number of encoding functions to use in the positional encoding
    # of the coordinates.
    num_encoding_fn_xyz: 10
    # Additionally use viewing directions as input.
    use_viewdirs: True
    # Whether to include the direction itself in its positional encoding.
    include_input_dir: False
    # Number of encoding functions to use in the positional encoding
    # of the direction.
    num_encoding_fn_dir: 4
    # Whether or not to perform log sampling in the positional encoding
    # of the direction.
    log_sampling_dir: True
  # Fine model.
  fine:
    # Name of the torch.nn.Module class that implements the model.
    type: ConditionalBlendshapePaperNeRFModel
    # Number of layers in the model.
    num_layers: 4
    # Number of hidden units in each layer of the MLP (multi-layer
    # perceptron).
    hidden_size: 256
    # Add a skip connection once in a while. Note: This parameter
    # won't take affect unless num_layers > skip_connect_every.
    skip_connect_every: 3
    # Number of encoding functions to use in the positional encoding
    # of the coordinates.
    num_encoding_fn_xyz: 10
    # Whether to include the position (xyz) itself in its positional
    # encoding.
    include_input_xyz: True
    # Whether or not to perform log sampling in the positional encoding
    # of the coordinates.
    log_sampling_xyz: True
    # Additionally use viewing directions as input.
    use_viewdirs: True
    # Whether to include the direction itself in its positional encoding.
    include_input_dir: False
    # Number of encoding functions to use in the positional encoding of
    # the direction.
    num_encoding_fn_dir: 4
    # Whether or not to perform log sampling in the positional encoding
    # of the direction.
    log_sampling_dir: True
  remove:
    type: ResnetGenerator_newupsample
    type2: ResnetGenerator_newupsample2
    type3: ResnetGenerator_newupsample3
    single: True
    if_remove: True
   # (input_nc, output_nc, ngf, norm_layer=norm_layer, use_dropout=use_dropout, n_blocks=9)
    input_nc: 64 # 512 + 3
    output_nc: 3
    ngf: 64
    transformer: False
  patchgan:
    input_dim_a: 3 #512
    input_dim_b: 3 #128
    dis_n_layer: 4

# Optimizer params.
optimizer:
  # Name of the torch.optim class used for optimization.
  type: Adam
  # Learning rate.
  lr: 1.0E-4
  lr2: 5.0E-5

# Learning rate schedule.
scheduler:
  # Exponentially decay learning rate (in 1000 steps)
  lr_decay: 250
  # Rate at which to apply this decay.
  lr_decay_factor: 0.1
  
# loss iters and weights
loss:
  coarse:
    loss_weight: 1
  fine:
    loss_weight: 1
  addloss:
    type: landmark, patchgan, remove, histogram
    iter: 1
    loss: True
  l2:
    l2_loss: False
    l2_iter: 5000
    l2_weight1: 1
    l2_weight2: 1
  landmark:
    landmark_loss: False
    start_iter: 0
    landmark_weight: 1
    n_local: 12
    # resize_scale: 0.8 # compared with 256
  patchgan:
    patchgan_loss: False
    new_patchgan_loss: True
    patchgan_content_loss: False
    patchgan_iter: 0
    patchgan_iter_weight: 500
    patchgan_g_style_weight1: 0.1
    patchgan_g_style_weight2: 0.1
    patchgan_g_content_weight1: 0.5
    patchgan_g_content_weight2: 0.5
  remove:
    start_iter: 0
    remove_loss: True
    remove_weight: 1
    ldmk_weight: 1
  depth:
    depth_loss: False
    depth_weight1: 10
    depth_weight2: 10
  histogram:
    histogram_loss: True
    histogram_loss_old: False
    histogram_weight: 10
    histogram_iter: 5000
  convolution:
    low_loss: False
    gen_loss: False
    gen_weight: 100

# NeRF parameters.
nerf:
  # Use viewing directions as input, in addition to the X, Y, Z coordinates.
  use_viewdirs: True
  # Encoding function for position (X, Y, Z).
  encode_position_fn: positional_encoding
  # Encoding function for ray direction (theta, phi).
  encode_direction_fn: positional_encoding
  # Training-specific parameters.
  train:
    # Number of random rays to retain from each image.
    # These sampled rays are used for training, and the others are discarded.
    num_random_rays: 1024  # 32 * 32 * 4 # was 1024
    # Size of each chunk (rays are batched into "chunks" and passed through
    # Size of each chunk (rays are batched into "chunks" and passed through
    # the network)
    chunksize: 1024 #16384  #131072  # 131072  # 1024 * 32
    # Whether or not to perturb the sampled depth values.
    perturb: True
    # Number of depth samples per ray for the coarse network.
    num_coarse: 64
    # Number of depth samples per ray for the fine network.
    num_fine: 64
    # Whether to render models using a white background.
    white_background: False
    # Standard deviation of noise to be added to the radiance field when
    # performing volume rendering.
    radiance_field_noise_std: 0.1
    # Sample linearly in disparity space, as opposed to in depth space.
    lindisp: False
  # Validation-specific parameters.
  validation:
    # Number of random rays to retain from each image.
    # These sampled rays are used for training, and the others are discarded.
    chunksize: 65536 #4096  #131072   # 1024 * 32
    # Whether or not to perturb the sampled depth values.
    perturb: True
    # Number of depth samples per ray for the coarse network.
    num_coarse: 64
    # Number of depth samples per ray for the fine network.
    num_fine: 64
    # Whether to render models using a white background.
    white_background: False
    # Standard deviation of noise to be added to the radiance field when
    # performing volume rendering.
    radiance_field_noise_std: 0.
    # Sample linearly in disparity space, as opposed to in depth space.
    lindisp: False

transformer:
    embed_dim: 256
    embed_patch_dim: 4096
    embed_cross_dim: 4096
    cross: True
    use_resnet: False
    if_global: True
    input_nc: 3
    output_nc: 3
    ngf: 64
    netG: TransEncoder
    norm: batch #instance
    no_dropout: False
    init_type: normal
    init_gain: 0.02
